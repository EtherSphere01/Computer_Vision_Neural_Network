{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Python\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_path=\"F:\\Model Data\\Imagedata\"\n",
    "Data_path2=\"F:\\Model Data\\AugmentedImageData\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        brightness_range=[0.5,1.2]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [12:24<00:00, 74.47s/it]\n",
      "100%|██████████| 10/10 [02:36<00:00, 15.66s/it]\n",
      "100%|██████████| 10/10 [09:10<00:00, 55.10s/it]\n",
      "100%|██████████| 10/10 [01:22<00:00,  8.25s/it]\n",
      "100%|██████████| 10/10 [05:09<00:00, 30.91s/it]\n",
      "100%|██████████| 10/10 [16:21<00:00, 98.19s/it]\n",
      "100%|██████████| 10/10 [00:35<00:00,  3.59s/it]\n",
      "100%|██████████| 10/10 [11:33<00:00, 69.32s/it]\n",
      "100%|██████████| 10/10 [06:04<00:00, 36.47s/it]\n",
      "100%|██████████| 10/10 [37:39<00:00, 225.95s/it]\n",
      "100%|██████████| 10/10 [08:32<00:00, 51.21s/it]\n",
      "100%|██████████| 10/10 [12:41<00:00, 76.12s/it]\n",
      "100%|██████████| 10/10 [08:57<00:00, 53.72s/it]\n",
      "100%|██████████| 10/10 [07:06<00:00, 42.61s/it]\n",
      "100%|██████████| 10/10 [02:38<00:00, 15.84s/it]\n",
      "100%|██████████| 10/10 [04:17<00:00, 25.77s/it]\n",
      "100%|██████████| 10/10 [03:18<00:00, 19.90s/it]\n",
      "100%|██████████| 10/10 [11:59<00:00, 71.92s/it]\n",
      "100%|██████████| 10/10 [01:41<00:00, 10.13s/it]\n",
      "100%|██████████| 10/10 [06:26<00:00, 38.62s/it]\n",
      "100%|██████████| 10/10 [02:41<00:00, 16.15s/it]\n",
      "100%|██████████| 10/10 [06:49<00:00, 40.90s/it]\n",
      "100%|██████████| 10/10 [17:34<00:00, 105.42s/it]\n",
      "100%|██████████| 10/10 [12:27<00:00, 74.73s/it]\n",
      "100%|██████████| 10/10 [14:40<00:00, 88.08s/it]\n",
      "100%|██████████| 10/10 [10:03<00:00, 60.32s/it]\n",
      "100%|██████████| 10/10 [01:45<00:00, 10.59s/it]\n",
      "100%|██████████| 10/10 [16:41<00:00, 100.20s/it]\n",
      "100%|██████████| 10/10 [15:32<00:00, 93.29s/it]\n",
      "100%|██████████| 10/10 [08:19<00:00, 49.93s/it]\n",
      "100%|██████████| 10/10 [18:26<00:00, 110.64s/it]\n",
      "100%|██████████| 10/10 [01:42<00:00, 10.28s/it]\n",
      "100%|██████████| 10/10 [01:50<00:00, 11.01s/it]\n",
      "100%|██████████| 10/10 [07:33<00:00, 45.32s/it]\n",
      "100%|██████████| 10/10 [01:42<00:00, 10.22s/it]\n",
      "100%|██████████| 10/10 [22:49<00:00, 136.96s/it]\n",
      "100%|██████████| 10/10 [00:53<00:00,  5.38s/it]\n"
     ]
    }
   ],
   "source": [
    "classes=os.listdir(Data_path)\n",
    "\n",
    "for i,c in enumerate(classes):\n",
    "    path = os.path.join(Data_path,c)\n",
    "    path2 = os.path.join(Data_path2,c)\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "        img_arr = cv2.imread(os.path.join(path,img))\n",
    "        x = img_to_array(img_arr)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "        j = 0\n",
    "        for batch in datagen.flow(x, batch_size=1,save_to_dir=path2, save_prefix=c, save_format='jpeg'):\n",
    "            j += 1\n",
    "            if j > 50:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:46<00:00, 10.67it/s]\n",
      "100%|██████████| 500/500 [00:13<00:00, 38.30it/s]\n",
      "100%|██████████| 500/500 [00:34<00:00, 14.60it/s]\n",
      "100%|██████████| 500/500 [00:10<00:00, 49.20it/s]\n",
      "100%|██████████| 500/500 [00:20<00:00, 24.10it/s]\n",
      "100%|██████████| 500/500 [00:56<00:00,  8.84it/s]\n",
      "100%|██████████| 500/500 [00:07<00:00, 63.90it/s]\n",
      "100%|██████████| 500/500 [00:40<00:00, 12.35it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.43it/s]\n",
      "100%|██████████| 500/500 [01:49<00:00,  4.56it/s]\n",
      "100%|██████████| 500/500 [00:31<00:00, 15.66it/s]\n",
      "100%|██████████| 500/500 [00:45<00:00, 10.99it/s]\n",
      "100%|██████████| 500/500 [00:34<00:00, 14.56it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.06it/s]\n",
      "100%|██████████| 500/500 [00:13<00:00, 38.06it/s]\n",
      "100%|██████████| 500/500 [00:19<00:00, 25.25it/s]\n",
      "100%|██████████| 500/500 [00:17<00:00, 28.84it/s]\n",
      "100%|██████████| 500/500 [00:41<00:00, 12.08it/s]\n",
      "100%|██████████| 500/500 [00:10<00:00, 49.50it/s]\n",
      "100%|██████████| 500/500 [00:28<00:00, 17.34it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 38.60it/s]\n",
      "100%|██████████| 500/500 [00:28<00:00, 17.71it/s]\n",
      "100%|██████████| 500/500 [01:00<00:00,  8.28it/s]\n",
      "100%|██████████| 500/500 [00:41<00:00, 12.00it/s]\n",
      "100%|██████████| 500/500 [00:51<00:00,  9.76it/s]\n",
      "100%|██████████| 500/500 [00:34<00:00, 14.45it/s]\n",
      "100%|██████████| 500/500 [00:11<00:00, 44.89it/s]\n",
      "100%|██████████| 500/500 [01:10<00:00,  7.14it/s]\n",
      "100%|██████████| 500/500 [00:53<00:00,  9.30it/s]\n",
      "100%|██████████| 500/500 [00:32<00:00, 15.37it/s]\n",
      "100%|██████████| 500/500 [00:58<00:00,  8.48it/s]\n",
      "100%|██████████| 500/500 [00:10<00:00, 47.58it/s]\n",
      "100%|██████████| 500/500 [00:10<00:00, 46.69it/s]\n",
      "100%|██████████| 500/500 [00:31<00:00, 15.89it/s]\n",
      "100%|██████████| 500/500 [00:10<00:00, 48.12it/s]\n",
      "100%|██████████| 500/500 [01:09<00:00,  7.18it/s]\n",
      "100%|██████████| 500/500 [00:08<00:00, 57.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "classes2=os.listdir(Data_path2)\n",
    "train_data=[]\n",
    "\n",
    "for i,c in enumerate(classes2):\n",
    "    path = os.path.join(Data_path2,c)\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "        img_arr = cv2.imread(os.path.join(path,img))\n",
    "        img_arr = cv2.resize(img_arr,(256,256))\n",
    "        train_data.append([img_arr,i])\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18500, 256, 256, 3) (18500,)\n"
     ]
    }
   ],
   "source": [
    "train_imgs=[]\n",
    "train_labels=[]\n",
    "\n",
    "for img,label in train_data:\n",
    "    train_imgs.append(img)\n",
    "    train_labels.append(label)\n",
    "\n",
    "train_imgs_np = np.array(train_imgs)\n",
    "train_labels_np = np.array(train_labels)\n",
    "print(train_imgs_np.shape, train_labels_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pout = open(\"F:/Model Data/Final Data Set/train_imgs.pickle\",\"wb\")\n",
    "pickle.dump(train_imgs_np,pout)\n",
    "pout.close()\n",
    "\n",
    "pout2 = open(\"F:/Model Data/Final Data Set/train_labels.pickle\",\"wb\")\n",
    "pickle.dump(train_labels_np,pout2)\n",
    "pout2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(classes2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pout = open(\"F:/Model Data/Final Data Set/train_imgs_np\",\"wb\")\n",
    "pickle.dump(train_imgs_np,pout)\n",
    "pout.close()\n",
    "\n",
    "pout2 = open(\"F:/Model Data/Final Data Set/train_labels_np\",\"wb\")\n",
    "pickle.dump(train_labels_np,pout2)\n",
    "pout2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
