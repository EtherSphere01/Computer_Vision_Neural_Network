{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Python\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_path=\"F:\\Model Data\\Imagedata\"\n",
    "Data_path2=\"F:\\Model Data\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 19.72it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 63.86it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.16it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 12.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.06it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 24.72it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.49it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.49it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.11it/s]\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.83it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.03it/s]\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 24.76it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.52it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.21it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.10it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classes=os.listdir(Data_path)\n",
    "test_classes=os.listdir(Data_path2)\n",
    "train_data=[]\n",
    "test_data=[]\n",
    "\n",
    "for i,c in enumerate(classes):\n",
    "    path = os.path.join(Data_path,c)\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "        img_arr = cv2.imread(os.path.join(path,img))\n",
    "        img_arr = cv2.resize(img_arr,(64,64))\n",
    "        train_data.append([img_arr,i])\n",
    "print(len(train_data))\n",
    "\n",
    "path = os.path.join(Data_path2)\n",
    "for img in tqdm(os.listdir(path)):\n",
    "    img_arr = cv2.imread(os.path.join(path,img))\n",
    "    img_arr = cv2.resize(img_arr,(64,64))\n",
    "    test_data.append(img_arr)\n",
    "print(len(test_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs=[]\n",
    "train_labels=[]\n",
    "test_imgs=[]\n",
    "for img,label in train_data:\n",
    "    train_imgs.append(img)\n",
    "    train_labels.append(label)\n",
    "    \n",
    "for img in test_data:\n",
    "    test_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 64, 64, 3) (190,) (9, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_imgs_np = np.array(train_imgs)\n",
    "train_labels_np = np.array(train_labels)\n",
    "test_imgs_np = np.array(test_imgs)\n",
    "print(train_imgs_np.shape, train_labels_np.shape,test_imgs_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Python\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From f:\\Python\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(64,64,3)),\n",
    "    tf.keras.layers.Conv2D(filters = 512, kernel_size=(5,5), padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters = 512, kernel_size=(5,5), padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units = 256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 3, activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 512)       38912     \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 512)       6554112   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 128)       589952    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 128)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33554688  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40754307 (155.47 MB)\n",
      "Trainable params: 40754307 (155.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Python\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = \"sparse_catagorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 252, in __call__\n        self.build(y_pred)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 194, in build\n        self._losses = tf.nest.map_structure(\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 365, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\losses.py\", line 2965, in get\n        return deserialize(identifier, use_legacy_format=use_legacy_format)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\losses.py\", line 2912, in deserialize\n        return legacy_serialization.deserialize_keras_object(\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\saving\\legacy\\serialization.py\", line 537, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: 'sparse_catagorical_crossentropy'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_imgs_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Python\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filex98389tu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 252, in __call__\n        self.build(y_pred)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 194, in build\n        self._losses = tf.nest.map_structure(\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 365, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\losses.py\", line 2965, in get\n        return deserialize(identifier, use_legacy_format=use_legacy_format)\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\losses.py\", line 2912, in deserialize\n        return legacy_serialization.deserialize_keras_object(\n    File \"f:\\Python\\Lib\\site-packages\\keras\\src\\saving\\legacy\\serialization.py\", line 537, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: 'sparse_catagorical_crossentropy'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "h = model.fit( x = train_imgs_np, y = train_labels_np, epochs = 2, validation_split = 0.2, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
